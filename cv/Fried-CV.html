<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="dcterms.date" content="2025-08-01" />
  <title>Daniel Fried: CV</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="style.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Daniel Fried: CV</h1>
<p class="date">August 01, 2025</p>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#contact-information" id="toc-contact-information">Contact
Information</a></li>
<li><a href="#positions" id="toc-positions">Positions</a></li>
<li><a href="#education" id="toc-education">Education</a></li>
<li><a href="#former-positions" id="toc-former-positions">Former
Positions</a></li>
<li><a href="#honors-awards" id="toc-honors-awards">Honors &amp;
Awards</a></li>
<li><a href="#section" id="toc-section"></a></li>
<li><a href="#students" id="toc-students">Students</a></li>
<li><a href="#teaching" id="toc-teaching">Teaching</a></li>
<li><a href="#invited-talks" id="toc-invited-talks">Invited
Talks</a></li>
<li><a href="#academic-service" id="toc-academic-service">Academic<br />
Service</a></li>
</ul>
</nav>
<h1 id="contact-information">Contact Information</h1>
<p><a
href="mailto:dfried@andrew.cmu.edu">dfried@andrew.cmu.edu</a><br />
<span><a href="dpfried.github.io"
class="uri">dpfried.github.io</a></span></p>
<h1 id="positions">Positions</h1>
<ul>
<li><p><strong>Assistant Professor</strong>, Carnegie Mellon University.
2022 – present<br />
Language Technologies Institute, School of Computer Science</p></li>
<li><p><strong>Research Scientist</strong>, Meta. 2024 – present<br />
</p></li>
</ul>
<h1 id="education">Education</h1>
<ul>
<li><p><strong>UC Berkeley</strong>. 2015 – 2021<br />
Ph.D. in Computer Science<br />
<em>Adviser</em>: Dan Klein<br />
<em>Thesis</em>: Learning Grounded Pragmatic Communication</p></li>
<li><p><strong>University of Cambridge</strong>, Churchill College. 2014
– 2015<br />
M.Phil. in Computer Science, <em>with distinction</em><br />
<em>Adviser</em>: Stephen Clark<br />
<em>Thesis</em>: Low Rank Tensor Approximations for Compositional
Distributional Semantics</p></li>
<li><p><strong>University of Arizona</strong>. 2010 – 2014<br />
B.S. in Computer Science, Mathematics, and Information Science,
<em>summa cum laude</em><br />
<em>Thesis Adviser</em>: Mihai Surdeanu<br />
<em>Thesis</em>: Predicting Community Traits Using the Language of Food
on Social Media</p></li>
</ul>
<h1 id="former-positions">Former Positions</h1>
<ul>
<li><p><strong>Postdoc</strong>, University of Washington. 2021 –
2022<br />
<em>Host</em>: Luke Zettlemoyer</p></li>
<li><p><strong>Visiting Researcher</strong>, Facebook AI Research. 2021
– 2022<br />
<em>Host</em>: Mike Lewis</p></li>
<li><p><strong>Research Intern</strong>, Google DeepMind. Summer
2019<br />
<em>Hosts</em>: Aida Nematzadeh, Stephen Clark, Chris Dyer<br />
<em>Project</em>: Structured models for language-conditioned video
segmentation</p></li>
<li><p><strong>Research Intern</strong>, Microsoft Research. Summer
2016<br />
<em>Hosts</em>: Hoifung Poon, Chris Quirk, Kristina Toutanova, Scott
Wen-Tau Yih<br />
<em>Project</em>: Learning to rank for personalized medicine</p></li>
<li><p><strong>Undergraduate Research Assistant</strong>, University of
Arizona. 2012 – 2014<br />
<em>Advisers</em>: Mihai Surdeanu, Stephen Kobourov, Paul R. Cohen<br />
<em>Areas</em>: Question answering, language grounding, data
visualization</p></li>
<li><p><strong>Research Intern</strong>, Nara Institute of Science and
Technology. Fall 2013<br />
<em>Host</em>: Kevin Duh<br />
<em>Project</em>: Incorporating relational semantics in word
embeddings</p></li>
<li><p><strong>Research Intern</strong>, RWTH Aachen University. Summer
2013<br />
<em>Hosts</em>: Ali Jannesari, Zhen Li<br />
<em>Project</em>: Supervised learning for automatic code
parallelization</p></li>
<li><p><strong>Engineering Intern</strong>, Microsoft. Summer 2012<br />
<em>Project</em>: Data warehousing, analytics, and visualization for
Xbox Live</p></li>
</ul>
<h1 id="honors-awards">Honors &amp; Awards</h1>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">Okawa Research Award</td>
<td style="text-align: right;">2023</td>
</tr>
<tr class="even">
<td style="text-align: left;">Google Ph.D. Fellowship in Natural
Language Processing</td>
<td style="text-align: right;">2019 – 2021</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Outstanding Graduate Student Instructor,
UC Berkeley</td>
<td style="text-align: right;">2018</td>
</tr>
<tr class="even">
<td style="text-align: left;">Outstanding Reviewer, ACL</td>
<td style="text-align: right;">2018, 2020, 2021, 2022</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Outstanding Reviewer, NeurIPS</td>
<td style="text-align: right;">2019</td>
</tr>
<tr class="even">
<td style="text-align: left;">Best M.Phil. Student Award, Cambridge
Computer Laboratory</td>
<td style="text-align: right;">2015</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Churchill Scholarship</td>
<td style="text-align: right;">2014 – 2015</td>
</tr>
<tr class="even">
<td style="text-align: left;">NDSEG Fellowship</td>
<td style="text-align: right;">2014</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Finalist, Hertz Graduate Fellowship</td>
<td style="text-align: right;">2014</td>
</tr>
<tr class="even">
<td style="text-align: left;">Outstanding Senior Award in Research, U.
Arizona College of Science</td>
<td style="text-align: right;">2014</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Outstanding Senior Award in Academics, U.
Arizona Computer Science</td>
<td style="text-align: right;">2014</td>
</tr>
<tr class="even">
<td style="text-align: left;">Outstanding Senior Award in Academics, U.
Arizona Information Science</td>
<td style="text-align: right;">2014</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Barry M. Goldwater Scholarship</td>
<td style="text-align: right;">2013</td>
</tr>
<tr class="even">
<td style="text-align: left;">National Merit Scholar</td>
<td style="text-align: right;">2010 – 2014</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Flinn Scholarship, Flinn Foundation of
Arizona</td>
<td style="text-align: right;">2010 – 2014</td>
</tr>
<tr class="even">
<td style="text-align: left;">Presidential Scholar, U.S. Department of
Education</td>
<td style="text-align: right;">2010</td>
</tr>
</tbody>
</table>
<h1 id="section"></h1>
<ol>
<li></li>
<li><p><a href="https://arxiv.org/abs/2305.06161"><strong>StarCoder: May
the Source Be With You!</strong></a><br />
Raymond Li et al. (68 authors from the BigCode Project)<br />
<em>Transactions on Machine Learning Research (TMLR)</em>, 2023</p></li>
<li><p><a
href="https://www.science.org/doi/10.1126/science.ade9097"><strong>Human-Level
Play in the Game of Diplomacy by Combining Language Models with
Strategic Reasoning</strong></a><br />
FAIR Diplomacy Team<br />
<em>Science</em>, 2022</p></li>
<li><p><a
href="https://www.mitpressjournals.org/doi/full/10.1162/tacl_a_00345"><strong>Syntactic
Structure Distillation Pretraining for Bidirectional
Encoders</strong></a><br />
Adhiguna Kuncoro*, Lingpeng Kong*, <u>Daniel Fried</u>*, Dani Yogatama,
Laura Rimell, Chris Dyer, and Phil Blunsom<br />
<em>Transactions of the Association for Computational Linguistics
(TACL)</em>, 2020</p></li>
<li><p><a
href="https://people.eecs.berkeley.edu/~dfried/papers/tacl2015-qa.pdf"><strong>Higher-Order
Lexical Semantic Models for Non-Factoid Answer
Reranking</strong></a><br />
<u>Daniel Fried</u>, Peter Jansen, Gustave Hahn-Powell, Mihai Surdeanu,
and Peter Clark<br />
<em>Transactions of the Association for Computational Linguistics
(TACL)</em>, 2015</p></li>
<li></li>
<li><p><a href="https://arxiv.org/abs/2504.06821"><strong>Inducing
Programmatic Skills for Agentic Tasks</strong></a><br />
Zora Zhiruo Wang, Apurva Gandhi, Graham Neubig, <u>Daniel
Fried</u><br />
<em>Conference on Language Modeling (COLM)</em>, 2025</p></li>
<li><p><a href="https://arxiv.org/abs/2503.07358"><strong>RepoST:
Scalable Repository-Level Coding Environment Construction with Sandbox
Testing</strong></a><br />
Yiqing Xie, Alex Xie, Divyanshu Sheth, Pengfei Liu, <u>Daniel Fried</u>,
Carolyn Rose<br />
<em>Conference on Language Modeling (COLM)</em>, 2025</p></li>
<li><p><a href="https://arxiv.org/abs/2410.18359"><strong>Improving
Model Factuality with Fine-grained Critique-based
Evaluator</strong></a><br />
Yiqing Xie, Wenxuan Zhou, Pradyot Prakash, Di Jin, Yuning Mao, Quintin
Fettes, Arya Talebzadeh, Sinong Wang, Han Fang, Carolyn Rose, <u>Daniel
Fried</u>, and Hejia Zhang<br />
<em>Annual Meeting of the Association for Computational Linguistics
(ACL)</em>, 2025</p></li>
<li><p><a href="https://arxiv.org/abs/2409.07429"><strong>Agent Workflow
Memory</strong></a><br />
Zora Zhiruo Wang, Jiayuan Mao, <u>Daniel Fried</u>, and Graham
Neubig<br />
<em>ICML</em>, 2025</p></li>
<li><p><a href="https://arxiv.org/abs/2502.16339"><strong>Dynamic
Coalition Structure Detection in Natural Language-based
Interactions</strong></a><br />
Abhishek N. Kulkarni*, Andy Liu*, Jean-Raphael Gaglione, <u>Daniel
Fried</u>, and Ufuk Topcu<br />
<em>International Conference on Autonomous Agents and Multiagent Systems
(AAMAS)</em>, 2025</p></li>
<li><p><a href="https://arxiv.org/abs/2501.00912"><strong>AutoPresent:
Designing Structured Visuals from Scratch</strong></a><br />
Jiaxin Ge*, Zora Zhiruo Wang*, Xuhui Zhou, Yi-Hao Peng, Sanjay
Subramanian, Qinyue Tan, Maarten Sap, Alane Suhr**, <u>Daniel
Fried</u>**, Graham Neubig**, and Trevor Darrell**<br />
<em>Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
2025</p></li>
<li><p><a href="https://arxiv.org/abs/2409.19801"><strong>CRScore:
Grounding Automated Evaluation of Code Review Comments in Code Claims
and Smells</strong></a><br />
Atharva Naik, Marcus Alenius, <u>Daniel Fried</u>, and Carolyn
Rose<br />
<em>North American Chapter of the Association for Computational
Linguistics (NAACL)</em>, 2025</p></li>
<li><p><a
href="https://arxiv.org/abs/2406.14497"><strong><span>CodeRAG-Bench</span>:
Can Retrieval Augment Code Generation?</strong></a><br />
Zora Zhiruo Wang*, Akari Asai*, Xinyan Velocity Yu, Frank F. Xu, Yiqing
Xie, Graham Neubig, and <u>Daniel Fried</u><br />
<em>Findings of NAACL</em>, 2025</p></li>
<li><p><a
href="https://arxiv.org/abs/2406.15877"><strong><span>BigCodeBench</span>:
Benchmarking Code Generation with Diverse Function Calls and Complex
Instructions</strong></a><br />
Terry Yue Zhuo et al. (33 authors from the BigCode project)<br />
<em>International Conference on Learning Representations (ICLR)</em>,
2025</p></li>
<li><p><a href="https://arxiv.org/abs/2410.03893"><strong>Human-Aligned
Chess with a Bit of Search</strong></a><br />
Yiming Zhang, Athul Paul Jacob, Vivian Lai, <u>Daniel Fried</u>, and
Daphne Ippolito<br />
<em>International Conference on Learning Representations (ICLR)</em>,
2025</p></li>
<li><p><a href="https://arxiv.org/abs/2402.15449"><strong>Repetition
Improves Language Model Embeddings</strong></a><br />
Jacob Mitchell Springer, Suhas Kotha, <u>Daniel Fried</u>, Graham
Neubig, and Aditi Raghunathan<br />
<em>International Conference on Learning Representations (ICLR)</em>,
2025</p></li>
<li><p><a href="https://arxiv.org/abs/2406.12814"><strong>Dissecting
Adversarial Robustness of Multimodal LM Agents</strong></a><br />
Chen Henry Wu, Rishi Shah, Jing Yu Koh, Ruslan Salakhutdinov, <u>Daniel
Fried</u>, and Aditi Raghunathan<br />
<em>International Conference on Learning Representations (ICLR)</em>,
2025</p></li>
<li><p><a href="https://arxiv.org/abs/2311.02253"><strong>Comparative
Knowledge Distillation</strong></a><br />
Alex Tianyi Xu*, Alex Wilf*, Paul Pu Liang, Alexander Obolenskiy,
<u>Daniel Fried</u>, and Louis-Philippe Morency<br />
<em>Winter Conference on Applications of Computer Vision (WACV)</em>,
2024</p></li>
<li><p><a href="http://arxiv.org/abs/2407.14044"><strong>ECCO: Can We
Improve Model-Generated Code Efficiency Without Sacrificing Functional
Correctness?</strong></a><br />
Siddhant Waghjale*, Vishruth Veerendranath*, Zora Zhiruo Wang, and
<u>Daniel Fried</u><br />
<em>Empirical Methods in Natural Language Processing (EMNLP)</em>,
2024</p></li>
<li><p><a href="http://arxiv.org/abs/2403.15452"><strong>What Are Tools
Anyway? A Survey from the Language Model Perspective</strong></a><br />
Zora Zhiruo Wang, Zhoujun Cheng, Hao Zhu, <u>Daniel Fried</u>, and
Graham Neubig<br />
<em>Conference on Language Modeling (COLM)</em>, 2024</p></li>
<li><p><a href="https://arxiv.org/abs/2405.14173"><strong>Human-Agent
Cooperation in Games under Incomplete Information through Natual
Language Communication</strong> </a><br />
Shenghui Chen, <u>Daniel Fried</u>, and Ufuk Topcu<br />
<em>International Joint Conference on Artificial Intelligence
(IJCAI)</em>, 2024</p></li>
<li><p><a href="https://arxiv.org/abs/2405.20253"><strong>Evaluating
Large Language Model Biases in Person-Steered
Generation</strong></a><br />
Andy Liu, Mona T. Diab, and <u>Daniel Fried</u><br />
<em>Findings of ACL</em>, 2024</p></li>
<li><p><a href="https://arxiv.org/abs/2405.08760"><strong>Is the Pope
Catholic? Yes, the Pope is Catholic. Generative Evaluation of Intent
Resolution in LLMs</strong></a><br />
Akhila Yerukola, Saujas Vaduguru, <u>Daniel Fried</u>, and Maarten
Sap<br />
<em>Annual Meeting of the Association for Computational Linguistics
(ACL)</em>, 2024</p></li>
<li><p><a
href="https://arxiv.org/abs/2401.13649"><strong>VisualWebArena:
Evaluating Multimodal Agents on Realistic Visual Web
Tasks</strong></a><br />
Jing Yu Koh, Robert Lo*, Lawrence Jang*, Vikram Duvvur*, Ming Chong
Lim*, Po-Yu Huang*, Graham Neubig, Shuyan Zhou, Ruslan Salakhutdinov,
and <u>Daniel Fried</u><br />
<em>Annual Meeting of the Association for Computational Linguistics
(ACL)</em>, 2024</p></li>
<li><p><a href="https://arxiv.org/abs/2401.12869"><strong>TroVE:
Inducing Verifiable and Efficient Toolboxes for Solving Programmatic
Tasks</strong></a><br />
Zhiruo Wang, Graham Neubig, and <u>Daniel Fried</u><br />
<em>International Conference on Machine Learning (ICML)</em>,
2024</p></li>
<li><p><a href="https://arxiv.org/abs/2407.02499"><strong>Amortizing
Pragmatic Program Synthesis with Rankings</strong></a><br />
Yewen Pu, Saujas Vaduguru, Priyan Vaithilingam, Elena Glassman, and
<u>Daniel Fried</u><br />
<em>International Conference on Machine Learning (ICML)</em>,
2024</p></li>
<li><p><a href="https://arxiv.org/abs/2311.08584"><strong>Asking More
Informative Questions for Grounded Retrieval</strong></a><br />
Sedrick Keh, Justin T. Chiu, and <u>Daniel Fried</u><br />
<em>Findings of NAACL</em>, 2024</p></li>
<li><p><a href="https://arxiv.org/abs/2311.05740"><strong>Generating
Pragmatic Examples to Train Neural Program
Synthesizers</strong></a><br />
Saujas Vaduguru, <u>Daniel Fried</u>, and Yewen Pu<br />
<em>International Conference on Learning Representations (ICLR)</em>,
2024</p></li>
<li><p><a href="http://arxiv.org/abs/2310.11667"><strong>Sotopia:
Interactive Evaluation for Social Intelligence in Language
Agents</strong></a><br />
Xuhui Zhou*, Hao Zhu*, Leena Mathur, Ruohong Zhang, Haofei Yu, Zhengyang
Qi, Louis-Philippe Morency, Yonatan Bisk, <u>Daniel Fried</u>, Graham
Neubig, and Maarten Sap<br />
<em>International Conference on Learning Representations (ICLR)</em>,
2024</p></li>
<li><p><a href="https://arxiv.org/abs/2307.13854"><strong>WebArena: A
Realistic Web Environment for Building Autonomous
Agents</strong></a><br />
Shuyan Zhou*, Frank Xu*, Hao Zhu**, Xuhui Zhou**, Robert Lo**, Abishek
Sridhar**, Xianyi Cheng, Yonatan Bisk, <u>Daniel Fried</u>, Uri Alon,
and Graham Neubig<br />
<em>International Conference on Learning Representations (ICLR)</em>,
2024</p></li>
<li><p><a href="https://arxiv.org/abs/2310.14687"><strong>API-Assisted
Code Generation for Question Answering on Varied Table
Structures</strong></a><br />
Yihan Cao*, Shuyi Chen*, Ryan Liu*, Zhiruo Wang, and <u>Daniel
Fried</u><br />
<em>Empirical Methods in Natural Language Processing (EMNLP)</em>,
2023</p></li>
<li><p><a href="https://arxiv.org/abs/2310.17140"><strong>Symbolic
Planning and Code Generation for Grounded Dialogue</strong> </a><br />
Justin Chiu, Wenting Zhao, Derek Chen, Saujas Vaduguru, Alexander Rush,
and <u>Daniel Fried</u><br />
<em>Empirical Methods in Natural Language Processing (EMNLP)</em>,
2023</p></li>
<li><p><a href="https://arxiv.org/abs/2211.08371"><strong>Pragmatics in
Language Grounding: Phenomena, Tasks, and Modeling
Approaches</strong></a><br />
<u>Daniel Fried</u>*, Nicholas Tomlin*, Jennifer Hu, Roma Patel, and
Aida Nematzadeh<br />
<em>Findings of EMNLP</em>, 2023</p></li>
<li><p><a
href="https://arxiv.org/abs/2212.10481"><strong>Execution-Based
Evaluation for Open-Domain Code Generation</strong></a><br />
Zhiruo Wang, Shuyan Zhou, <u>Daniel Fried</u>, and Graham Neubig<br />
<em>Findings of EMNLP</em>, 2023</p></li>
<li><p><a href="https://arxiv.org/abs/2311.00317"><strong>Data
Augmentation for Code Translation with Comparable Corpora and Multiple
References</strong></a><br />
Yiqing Xie, Atharva Naik, <u>Daniel Fried</u>, Carolyn Rose<br />
<em>Findings of EMNLP</em>, 2023</p></li>
<li><p><a href="https://arxiv.org/abs/2211.12615"><strong>AutoReply:
Detecting Nonsense in Dialogue Introspectively with Discriminative
Replies</strong></a><br />
Weiyan Shi, Emily Dinan, Adi Renduchintala, <u>Daniel Fried</u>, Athul
Paul Jacob, Zhou Yu, and Mike Lewis<br />
<em>Findings of EMNLP</em>, 2023</p></li>
<li><p><a href="https://arxiv.org/abs/2305.17216"><strong>Generating
Images with Multimodal Language Models</strong></a><br />
Jing Yu Koh, <u>Daniel Fried</u>, and Ruslan Salakhutdinov<br />
<em>Neural Information Processing Systems (NeurIPS)</em>, 2023</p></li>
<li><p><a href="https://arxiv.org/abs/2306.08818"><strong>Pragmatic
Inference with a CLIP Listener for Contrastive
Captioning</strong></a><br />
Jiefu Ou, Benno Krojer, and <u>Daniel Fried</u><br />
<em>Findings of ACL</em>, 2023</p></li>
<li><p><a href="https://arxiv.org/abs/2210.15097"><strong>Contrastive
Decoding: Open-ended Text Generation as Optimization</strong></a><br />
Xiang Lisa Li, Ari Holtzman, <u>Daniel Fried</u>, Percy Liang, Jason
Eisner, Tatsunori Hashimoto, Luke Zettlemoyer, and Mike Lewis<br />
<em>Annual Meeting of the Association for Computational Linguistics
(ACL)</em>, 2023</p></li>
<li><p><a href="https://arxiv.org/abs/2301.13823"><strong>Grounding
Language Models to Images for Multimodal Inputs and
Outputs</strong></a><br />
Jing Yu Koh, Ruslan Salakhutdinov, and <u>Daniel Fried</u><br />
<em>International Conference on Machine Learning (ICML)</em>,
2023</p></li>
<li><p><a href="https://arxiv.org/abs/2211.16490"><strong>Coder Reviewer
Reranking for Code Generation</strong></a><br />
Tianyi Zhang, Tao Yu, Tatsunori B. Hashimoto, Mike Lewis, Wen-tau Yih,
<u>Daniel Fried</u>, and Sida I. Wang<br />
<em>International Conference on Machine Learning (ICML)</em>,
2023</p></li>
<li><p><a href="https://arxiv.org/abs/2211.11501"><strong>DS-1000: A
Natural and Reliable Benchmark for Data Science Code
Generation</strong></a><br />
Yuhang Lai*, Chengxi Li*, Yiming Wang*, Tianyi Zhang*, Ruiqi Zhong*,
Luke Zettlemoyer, Scott Wen-tau Yih, <u>Daniel Fried</u>, Sida I. Wang,
and Tao Yu<br />
<em>International Conference on Machine Learning (ICML)</em>,
2023</p></li>
<li><p><a href="https://arxiv.org/abs/2204.05999"><strong>InCoder: A
Generative Model for Code Infilling and Synthesis</strong></a><br />
<u>Daniel Fried</u>*, Armen Aghajanyan*, Jessy Lin, Sida I. Wang, Eric
Wallace, Freda Shi, Ruiqi Zhong, Wen-tau Yih, Luke Zettlemoyer, and Mike
Lewis<br />
<em>International Conference on Learning Representations (ICLR)</em>,
2023</p></li>
<li><p><a href="https://arxiv.org/abs/2204.11454"><strong>Natural
Language to Code Translation with Execution</strong></a><br />
Freda Shi, <u>Daniel Fried</u>, Marjan Ghazvininejad, Luke Zettlemoyer,
and Sida I. Wang<br />
<em>Empirical Methods in Natural Language Processing (EMNLP)</em>,
2022</p></li>
<li><p><a href="https://arxiv.org/abs/2210.13312"><strong>Neural
Theory-of-Mind? On the Limits of Social Intelligence in Large
LMs</strong></a><br />
Maarten Sap, Ronan Le Bras, <u>Daniel Fried</u>, and Yejin Choi<br />
<em>Empirical Methods in Natural Language Processing (EMNLP)</em>,
2022</p></li>
<li><p><a href="https://arxiv.org/abs/2211.15521"><strong>G3:
Geolocation via Guidebook Grounding</strong></a><br />
Grace Luo*, Giscard Biamby*, Trevor Darrell, <u>Daniel Fried</u>, and
Anna Rohrbach<br />
<em>Findings of EMNLP</em>, 2022</p></li>
<li><p><a href="https://arxiv.org/abs/2204.02515"><strong>Inferring
Rewards from Language in Context</strong></a><br />
Jessy Lin, <u>Daniel Fried</u>, Dan Klein, and Anca Dragan<br />
<em>Annual Meeting of the Association for Computational Linguistics
(ACL)</em>, 2022</p></li>
<li><p><a
href="https://arxiv.org/abs/2109.05042"><strong>Reference-Centric Models
for Grounded Collaborative Dialogue</strong></a><br />
<u>Daniel Fried</u>, Justin Chiu, and Dan Klein<br />
<em>Empirical Methods in Natural Language Processing (EMNLP)</em>,
2021</p></li>
<li><p><a href="https://arxiv.org/abs/2010.12764"><strong>Modular
Networks for Compositional Instruction Following</strong></a><br />
Rodolfo Corona, <u>Daniel Fried</u>, Coline Devin, Dan Klein, and Trevor
Darrell<br />
<em>North American Chapter of the Association for Computational
Linguistics (NAACL)</em>, 2021</p></li>
<li><p><a href="https://arxiv.org/abs/2005.03684"><strong>Learning to
Segment Actions from Observation and Narration</strong></a><br />
<u>Daniel Fried</u>, Jean-Baptiste Alayrac, Phil Blunsom, Chris Dyer,
Stephen Clark, Aida Nematzadeh<br />
<em>Annual Meeting of the Association for Computational Linguistics
(ACL)</em>, 2020</p></li>
<li><p><a href="https://arxiv.org/abs/1907.04347"><strong>Cross-Domain
Generalization of Neural Constituency Parsers</strong></a><br />
<u>Daniel Fried</u>*, Nikita Kitaev*, and Dan Klein<br />
<em>Annual Meeting of the Association for Computational Linguistics
(ACL)</em>, 2019</p></li>
<li><p><a href="https://arxiv.org/abs/1906.00347"><strong>Are You
Looking? Grounding to Multiple Modalities in Vision-and-Language
Navigation</strong></a><br />
Ronghang Hu, <u>Daniel Fried</u>, Anna Rohrbach, Dan Klein, Trevor
Darrell, and Kate Saenko<br />
<em>Annual Meeting of the Association for Computational Linguistics
(ACL)</em>, 2019</p></li>
<li><p><a href="https://arxiv.org/abs/1904.01301"><strong>Pragmatically
Informative Text Generation</strong></a><br />
Sheng Shen, <u>Daniel Fried</u>, Jacob Andreas, and Dan Klein<br />
<em>North American Chapter of the Association for Computational
Linguistics (NAACL)</em>, 2019</p></li>
<li><p><a
href="https://arxiv.org/abs/1806.02724"><strong>Speaker-Follower Models
for Vision-and-Language Navigation</strong></a><br />
<u>Daniel Fried</u>*, Ronghang Hu*, Volkan Cirik*, Anna Rohrbach, Jacob
Andreas, Louis-Philippe Morency, Taylor Berg-Kirkpatrick, Kate Saenko,
Dan Klein**, and Trevor Darrell**<br />
<em>Neural Information Processing Systems (NeurIPS)</em>, 2018</p></li>
<li><p><a href="https://arxiv.org/abs/1806.03290"><strong>Policy
Gradient as a Proxy for Dynamic Oracles in Constituency
Parsing</strong></a><br />
<u>Daniel Fried</u> and Dan Klein<br />
<em>Annual Meeting of the Association for Computational Linguistics
(ACL)</em>, 2018</p></li>
<li><p><a href="https://arxiv.org/abs/1711.04987"><strong>Unified
Pragmatic Models for Generating and Following
Instructions</strong></a><br />
<u>Daniel Fried</u>, Jacob Andreas, and Dan Klein<br />
<em>North American Chapter of the Association for Computational
Linguistics (NAACL)</em>, 2018</p></li>
<li><p><a href="http://arxiv.org/abs/1707.08976"><strong>Effective
Inference for Generative Neural Parsing</strong></a><br />
Mitchell Stern, <u>Daniel Fried</u>, and Dan Klein<br />
<em>Empirical Methods in Natural Language Processing (EMNLP)</em>,
2017</p></li>
<li><p><a href="https://arxiv.org/abs/1707.03058"><strong>Improving
Neural Parsing by Disentangling Model Combination and Reranking
Effects</strong></a><br />
<u>Daniel Fried</u>*, Mitchell Stern*, and Dan Klein<br />
<em>Annual Meeting of the Association for Computational Linguistics
(ACL)</em>, 2017</p></li>
<li><p><a href="http://arxiv.org/abs/1603.03784"><strong>Towards Using
Social Media to Identify Individuals at Risk for Preventable Chronic
Illness</strong></a><br />
Dane Bell, <u>Daniel Fried</u>, Luwen Huangfu, Mihai Surdeanu, and
Stephen Kobourov<br />
<em>Language Resources and Evaluation Conference (LREC)</em>,
2016</p></li>
<li><p><a
href="https://people.eecs.berkeley.edu/~dfried/papers/FPC-verb_tensors.pdf"><strong>Low-Rank
Tensors for Verbs in Compositional Distributional
Semantics</strong></a><br />
<u>Daniel Fried</u>, Tamara Polajnar, and Stephen Clark<br />
<em>Annual Meeting of the Association for Computational Linguistics
(ACL)</em>, 2015</p></li>
<li><p><a
href="https://people.eecs.berkeley.edu/~dfried/papers/Fried-bigdata2014.pdf"><strong>Analyzing
the Language of Food on Social Media</strong></a><br />
<u>Daniel Fried</u>, Mihai Surdeanu, Stephen Kobourov, Melanie Hingle,
and Dane Bell<br />
<em>International Conference on Big Data</em>, 2014</p></li>
<li><p><a href="https://arxiv.org/abs/1304.2681"><strong>Maps of
Computer Science</strong></a><br />
<u>Daniel Fried</u> and Stephen Kobourov<br />
<em>Pacific Visualization Symposium (PacificVis)</em>, 2014</p></li>
<li><p><a
href="https://people.eecs.berkeley.edu/~dfried/papers/Fried-ICMLA2013.pdf"><strong>Predicting
Parallelization of Sequential Programs Using Supervised
Learning</strong></a><br />
<u>Daniel Fried</u>, Zhen Li, Ali Jannesari, and Felix Wolf<br />
<em>International Conference on Machine Learning and Applications</em>,
2013</p></li>
<li><p><a
href="https://people.eecs.berkeley.edu/~dfried/papers/ICDL2013.pdf"><strong>A
Generative Probabilistic Framework for Learning Spatial
Language</strong></a><br />
Colin Dawson, Jeremy Wright, Antons Rebguns, Marco Valenzuela Escarcega,
<u>Daniel Fried</u>, and Paul Cohen<br />
<em>International Conference on Development and Learning</em>, 2013.
<strong>Best Paper Award</strong></p></li>
<li><p><a
href="https://people.eecs.berkeley.edu/~dfried/papers/Del-Pero-CVPR-12.pdf"><strong>Bayesian
Geometric Modeling of Indoor Scenes</strong></a><br />
Luca Del Pero, Joshua Bowdish, <u>Daniel Fried</u>, Bonnie Kermgard,
Emily Hartley, and Kobus Barnard<br />
<em>Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
2012</p></li>
<li></li>
<li><p><a
href="SantaCoder: Don&#39;t Reach for the Stars"><strong>SantaCoder:
Don’t Reach for the Stars</strong></a><br />
Loubna Ben Allal*, Raymond Li*, Denis Kocetkov*, et al. (41 authors from
the BigCode Project)<br />
<em>Deep Learning for Code Workshop</em>, 2023. <strong>Best Paper
Award</strong></p></li>
<li><p><a
href="https://openreview.net/pdf?id=PkHSHZLig5H"><strong>Modeling
Perspective-Dependent Ambiguity in Grounded Collaborative
Dialogue</strong></a><br />
Justin Chiu, Wenting Zhao, Alexander M. Rush, and <u>Daniel
Fried</u><br />
<em>Wordplay: When Language Meets Games Workshop</em>, 2022</p></li>
<li><p><a
href="http://nlp.cs.berkeley.edu/pubs/Gaddy-Fried-Kitaev-Stern-Corona-DeNero-Klein_2021_TeachingNLP_paper.pdf"><strong>Interactive
Assignments for Teaching Structured Neural NLP</strong></a><br />
David Gaddy, <u>Daniel Fried</u>, Nikita Kitaev, Mitchell Stern, Rodolfo
Corona, John DeNero, and Dan Klein<br />
<em>Teaching NLP Workshop at NAACL</em>, 2021</p></li>
<li><p><strong>Challenges for Using Social Media for Early Detection of
Type II Diabetes Mellitus</strong><br />
Dane Bell, <u>Daniel Fried</u>, Luwen Huangfu, Mihai Surdeanu, and
Stephen Kobourov<br />
<em>International Workshop on Social Media World Sensors</em>,
2016</p></li>
<li><p><strong>Learning Low-Rank Tensors for Transitive
Verbs</strong><br />
<u>Daniel Fried</u>, Tamara Polajnar, and Stephen Clark<br />
<em>Advances in Distributional Semantics Workshop</em>, 2015</p></li>
<li><p><a href="http://arxiv.org/abs/1412.5836"><strong>Incorporating
both Distributional and Relational Semantics in Word
Representations</strong></a><br />
<u>Daniel Fried</u> and Kevin Duh<br />
<em>International Conference on Learning Representations (ICLR)
Workshop</em>, 2015</p></li>
<li></li>
<li><p><a href="https://arxiv.org/abs/2506.19724"><strong>From
Reproduction to Replication: Evaluating Research Agents with Progressive
Code Masking</strong></a><br />
Gyeongwon James Kim, Alex Wilf, Louis-Philippe Morency, <u>Daniel
Fried</u><br />
<em>arXiv</em>, 2025</p></li>
<li><p><a href="https://arxiv.org/abs/2506.02355"><strong>Rewarding the
Unlikely: Lifting GRPO Beyond Distribution Sharpening</strong></a><br />
Andre He, <u>Daniel Fried</u>, and Sean Welleck<br />
<em>arXiv</em>, 2025</p></li>
<li><p><a href="https://arxiv.org/abs/2504.20294"><strong>mrCAD:
Multimodal Refinement of Computer-aided Designs</strong></a><br />
William P. McCarthy, Saujas Vaduguru, Karl D. D. Willis, Justin Matejka,
Judith E. Fan, <u>Daniel Fried</u>, and Yewen Pu<br />
<em>arXiv</em>, 2025</p></li>
<li><p><a href="https://arxiv.org/abs/2502.18449"><strong>SWE-RL:
Advancing LLM Reasoning via Reinforcement Learning on Open Software
Evolution</strong></a><br />
Yuxiang Wei, Olivier Duchenne, Jade Copet, Quentin Carbonneaux, Lingming
Zhang, <u>Daniel Fried</u>, Gabriel Synnaeve, Rishabh Singh, and Sida I.
Wang<br />
<em>arXiv</em>, 2025</p></li>
<li><p><a href="https://arxiv.org/abs/2404.00566"><strong>CodeBenchGen:
Creating Scalable Execution-based Code Generation
Benchmarks</strong></a><br />
Yiqing Xie, Alex Xie, Divyanshu Sheth, Pengfei Liu, <u>Daniel Fried</u>,
and Carolyn Rose<br />
<em>arXiv</em>, 2024</p></li>
<li><p><a href="https://arxiv.org/abs/2407.01476"><strong>Tree Search
for Language Model Agents</strong></a><br />
Jing Yu Koh, Stephen McAleer, <u>Daniel Fried</u>, and Ruslan
Salakhutdinov<br />
<em>arXiv</em>, 2024</p></li>
</ol>
<p><strong>*,**</strong>: equal contribution</p>
<h1 id="students">Students</h1>
<p>PhD thesis advisor:</p>
<ul>
<li><p>Andre He (with Sean Welleck)</p></li>
<li><p>Jing Yu (JY) Koh (with Ruslan Salakhutdinov)</p></li>
<li><p>Andy Liu (with Mona Diab)</p></li>
<li><p>Saujas Vaduguru</p></li>
<li><p>Zhiruo (Zora) Wang (with Graham Neubig)</p></li>
</ul>
<p>MLT thesis advisor:</p>
<ul>
<li><p>Alex Xie (with Matt Gormley and Vincent Hellendoorn)</p></li>
</ul>
<p>PhD committee member:</p>
<ul>
<li><p>Shuyan Zhou</p></li>
<li><p>Aman Madaan</p></li>
<li><p>Ta-Chung Chi</p></li>
<li><p>Nikitha Rao</p></li>
<li><p>Frank Xu</p></li>
<li><p>Ritam Dutt</p></li>
<li><p>Ruohong Zhang</p></li>
<li><p>So Yeon (Tiffany) Min</p></li>
<li><p>Anthony Sicilia (Northeastern)</p></li>
<li><p>Kush Jain</p></li>
<li><p>Brendon Boldt</p></li>
<li><p>Sanjay Subramanian (UC Berkeley)</p></li>
</ul>
<h1 id="teaching">Teaching</h1>
<ul>
<li><p><strong><em>Instructor:</em> 11-891, Neural Code
Generation</strong>, CMU, Spring 2024</p></li>
<li><p><strong><em>Instructor:</em> 11-877, Advanced Multimodal Machine
Learning</strong>, CMU, Spring 2024</p></li>
<li><p><strong><em>Instructor:</em> 11-711, Advanced NLP</strong>, CMU,
Fall 2023</p></li>
<li><p><strong><em>Instructor:</em> 11-777, Multimodal Machine
Learning</strong>, CMU, 2023 – present</p></li>
<li><p><strong><em>Instructor:</em> CS188, Artificial
Intelligence</strong>, UC Berkeley, Summer 2018</p></li>
<li><p><strong><em>Teaching Assistant:</em> CS188, Artificial
Intelligence</strong>, UC Berkeley, Fall 2017</p></li>
<li><p><strong><em>Teaching Assistant:</em> CS245, Intro to Discrete
Structures</strong>, University of Arizona, Spring 2012</p></li>
<li><p><strong><em>Teaching Assistant:</em> ISTA100, Great Ideas of the
Information Age</strong>, University of Arizona, Fall 2011</p></li>
<li><p><strong><em>Project Design:</em> CS288, Natural Language
Processing</strong>, UC Berkeley, Spring 2020</p></li>
</ul>
<h1 id="invited-talks">Invited Talks</h1>
<ul>
<li><p><em>Improving NLP Systems with Speaker Listener Games</em>.
Society for Computation in Linguistics (SCiL) 2025.</p></li>
<li><p><em>Inducing Functions to Improve LLM Agents</em>. Deep Learning
For Code Workshop, ICLR 2025; REALM Workshop, ACL 2025.</p></li>
<li><p><em>Planning and Inferring with LLMs for Grounded, Interactive
Tasks</em>. Forum for Artificial Intelligence, UT Austin. Fall
2024</p></li>
<li><p><em>Benchmarks and Tree Search for Multimodal LLM Agents</em>.
SpLU-RoboNLP Workshop, ACL 2024. Summer 2024</p></li>
<li><p><em>Interacting with LLMs for Grounded Tasks</em>. NILLI
Workshop, EMNLP 2023. Spring 2023</p></li>
<li><p><em>Interacting with (code) LLMs</em>. MIT Neurosymbolic Reading
Group. Spring 2023</p></li>
<li><p><em>InCoder, SantaCoder, and StarCoder: Findings from Training
Open-Source Code LLMs</em>. Bloomberg AI; GitHub Next. Spring
2023</p></li>
<li><p><em>Using Language Strategically in Context</em>. CoRL Workshop
on Strategic Multi-Agent Interactions, 2022; Johns Hopkins University,
University of Pennsylvania, UT Austin. Spring 2023</p></li>
<li><p><em>Contextual Communication in Programming</em>. LTI Future of
Code Generation Seminar, 2022</p></li>
<li><p><em>Reasoning About Actions and Rewards in Language
Interactions</em>. MIT CPL, 2022. (with Jessy Lin)</p></li>
<li><p><em>Modularity in Grounded Interaction</em>. ViGIL Workshop,
NAACL 2021. (with Rudy Corona)</p></li>
<li><p><em>Learning Grounded Pragmatic Communication</em>. University of
Arizona, TTI-Chicago, University of Southern California, Purdue,
Carnegie Mellon University, UC Irvine, Université de Montréal/Mila,
Allen Institute for Artificial Intelligence, Facebook AI Research,
Google Research, Stanford Cognition and Language Workshop. Spring
2021</p></li>
<li><p><em>Pragmatic Models for Generating and Following Grounded
Instructions</em>. Stanford NLP Seminar, University of Arizona, USC ISI.
Fall 2018–Spring 2019</p></li>
</ul>
<h1 id="academic-service">Academic<br />
Service</h1>
<ul>
<li><p><strong>Workshop co-organizer</strong>: Workshop on Large
Language Models for Agents, ICLR 2024</p></li>
<li><p><strong>Workshop co-organizer</strong>: 3rd UnImplicit Workshop,
EACL 2024</p></li>
<li><p><strong>Workshop co-organizer</strong>: 2nd UnImplicit Workshop,
NAACL 2022</p></li>
<li><p><strong>Workshop co-organizer</strong>: 2nd Advances in Language
and Vision Workshop, NAACL 2021</p></li>
<li><p><strong>Workshop advisory board</strong>: Theory of Mind in
Communicating Agents, ICML 2023</p></li>
<li><p><strong>Outstanding reviewer awards</strong>: ACL 2018, NeurIPS
2019, ACL 2020, ACL 2021, ACL 2022</p></li>
<li><p><strong>Senior area chair</strong>: ACL 2024</p></li>
<li><p><strong>Area chair</strong>: EMNLP 2022–2024, ACL 2023</p></li>
<li><p><strong>Ethics chair</strong>: NAACL 2024</p></li>
<li><p><strong>Reviewing</strong>: TACL 2022–2024; ACL Rolling Review
2021–2023; ACL 2018–2022; EMNLP 2016–2021; NAACL 2019, 2021; AACL-IJCNLP
2020; EACL 2017, 2021; NeurIPS 2019–2023; ICML 2019, 2023; ICLR
2021–2023; AKBC 2021; COLING 2018; *SEM 2016–2018; NAACL-SRW 2016, 2018;
ACL-SRW 2020; IJCAI 2016; SpLU-RoboNLP 2019, 2021; NeuralGen 2019; ViGIL
2019, 2021; DeepLo 2019; ALVR 2020, 2021; LaReL 2020; Cooperative AI
2021; Meaning in Context 2021<br />
</p></li>
</ul>
</body>
</html>
